{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Ratings_exercise.xlsx')\n",
    "\n",
    "features = data[['rel_size', 'excess_rets', 'idio_stdev', 'ni_ta', 'tl_ta']]\n",
    "labels = data['ratings9'].astype(int)  \n",
    "\n",
    "unique_ratings = sorted(labels.unique())\n",
    "rating_to_idx = {r: i for i, r in enumerate(unique_ratings)}\n",
    "labels = labels.map(rating_to_idx)\n",
    "num_classes = len(unique_ratings)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X = features_scaled\n",
    "y = labels.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2717, 5)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2717,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X.shape[1]      # number of predictors (5)\n",
    "hidden_dim = 10000             # hidden layer size (adjustable)\n",
    "output_dim = num_classes    # number of classes\n",
    "num_epochs = 100            # training epochs\n",
    "learning_rate = 0.001       # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    print(f\"Fold {fold}\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "    \n",
    "    model = FeedforwardNN(input_dim, hidden_dim, output_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.6317\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.67      0.29      0.40         7\n",
      "           2       0.50      0.39      0.44        41\n",
      "           3       0.66      0.69      0.67       167\n",
      "           4       0.56      0.64      0.60       152\n",
      "           5       0.72      0.72      0.72       147\n",
      "           6       1.00      0.20      0.33        25\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.63       543\n",
      "   macro avg       0.57      0.44      0.46       543\n",
      "weighted avg       0.65      0.63      0.62       543\n",
      "\n",
      "Neural Network Confusion Matrix:\n",
      "[[  1   0   0   0   0   0   0   0   0]\n",
      " [  0   2   5   0   0   0   0   0   0]\n",
      " [  0   0  16  23   2   0   0   0   0]\n",
      " [  0   1  10 116  37   3   0   0   0]\n",
      " [  0   0   0  35  97  20   0   0   0]\n",
      " [  0   0   1   2  38 106   0   0   0]\n",
      " [  0   0   0   1   0  17   5   1   1]\n",
      " [  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0   1   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "\n",
    "nn_acc = accuracy_score(y_test, predicted.numpy())\n",
    "print(f\"Neural Network Accuracy: {nn_acc:.4f}\")\n",
    "\n",
    "unique_labels_fold = np.unique(np.concatenate((y_test, predicted.numpy())))\n",
    "print(\"Neural Network Classification Report:\")\n",
    "print(classification_report(y_test, predicted.numpy(), labels=unique_labels_fold,\n",
    "                            target_names=[str(l) for l in unique_labels_fold]))\n",
    "print(\"Neural Network Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predicted.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6206\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.33      0.14      0.20         7\n",
      "           2       0.55      0.29      0.38        41\n",
      "           3       0.64      0.74      0.69       167\n",
      "           4       0.55      0.61      0.57       152\n",
      "           5       0.70      0.70      0.70       147\n",
      "           6       0.71      0.20      0.31        25\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.62       543\n",
      "   macro avg       0.39      0.30      0.32       543\n",
      "weighted avg       0.62      0.62      0.61       543\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[  0   1   0   0   0   0   0   0   0]\n",
      " [  0   1   4   2   0   0   0   0   0]\n",
      " [  0   0  12  26   3   0   0   0   0]\n",
      " [  0   1   6 124  35   1   0   0   0]\n",
      " [  0   0   0  37  92  23   0   0   0]\n",
      " [  0   0   0   5  38 103   1   0   0]\n",
      " [  0   0   0   1   0  18   5   1   0]\n",
      " [  0   0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "logit_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "logit_model.fit(X_train, y_train)\n",
    "logit_pred = logit_model.predict(X_test)\n",
    "logit_acc = accuracy_score(y_test, logit_pred)\n",
    "print(f\"Logistic Regression Accuracy: {logit_acc:.4f}\")\n",
    "\n",
    "unique_labels_fold_logit = np.unique(np.concatenate((y_test, logit_pred)))\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, logit_pred, labels=unique_labels_fold_logit,\n",
    "                            target_names=[str(l) for l in unique_labels_fold_logit]))\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, logit_pred))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "fold_results.append({'nn_acc': nn_acc, 'logit_acc': logit_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Neural Network Accuracy: 0.6317\n",
      "Average Logistic Regression Accuracy: 0.6206\n"
     ]
    }
   ],
   "source": [
    "nn_avg_acc = np.mean([res['nn_acc'] for res in fold_results])\n",
    "logit_avg_acc = np.mean([res['logit_acc'] for res in fold_results])\n",
    "print(f\"Average Neural Network Accuracy: {nn_avg_acc:.4f}\")\n",
    "print(f\"Average Logistic Regression Accuracy: {logit_avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Ratings_exercise.xlsx')\n",
    "\n",
    "features = data[['rel_size', 'excess_rets', 'idio_stdev', 'ni_ta', 'tl_ta']]\n",
    "labels = data['ratings9'].astype(int)\n",
    "\n",
    "unique_ratings = sorted(labels.unique())\n",
    "rating_to_idx = {r: i for i, r in enumerate(unique_ratings)}\n",
    "labels = labels.map(rating_to_idx)\n",
    "num_classes = len(unique_ratings)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X = features_scaled\n",
    "y = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "input_dim = X.shape[1]      \n",
    "hidden_dim = 10000 \n",
    "output_dim = num_classes    \n",
    "num_epochs = 100            \n",
    "learning_rate = 0.001       \n",
    "\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.LongTensor(y)\n",
    "\n",
    "model = FeedforwardNN(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.6643\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         6\n",
      "           1       0.73      0.49      0.58        39\n",
      "           2       0.63      0.38      0.47       254\n",
      "           3       0.65      0.72      0.68       797\n",
      "           4       0.63      0.68      0.65       853\n",
      "           5       0.73      0.74      0.73       670\n",
      "           6       0.77      0.48      0.59        86\n",
      "           7       0.00      0.00      0.00         5\n",
      "           8       1.00      0.29      0.44         7\n",
      "\n",
      "    accuracy                           0.66      2717\n",
      "   macro avg       0.68      0.46      0.52      2717\n",
      "weighted avg       0.67      0.66      0.66      2717\n",
      "\n",
      "Neural Network Confusion Matrix:\n",
      "[[  2   4   0   0   0   0   0   0   0]\n",
      " [  0  19  14   6   0   0   0   0   0]\n",
      " [  0   1  97 137  16   3   0   0   0]\n",
      " [  0   1  41 572 169  14   0   0   0]\n",
      " [  0   1   3 150 579 120   0   0   0]\n",
      " [  0   0   0  13 157 493   7   0   0]\n",
      " [  0   0   0   0   3  42  41   0   0]\n",
      " [  0   0   0   0   0   3   2   0   0]\n",
      " [  0   0   0   0   0   1   3   1   2]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "nn_acc = accuracy_score(y, predicted.numpy())\n",
    "print(\"Neural Network Accuracy: {:.4f}\".format(nn_acc))\n",
    "print(\"Neural Network Classification Report:\")\n",
    "print(classification_report(y, predicted.numpy(), target_names=[str(r) for r in unique_ratings]))\n",
    "print(\"Neural Network Confusion Matrix:\")\n",
    "print(confusion_matrix(y, predicted.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.6150\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.72      0.33      0.46        39\n",
      "           2       0.58      0.26      0.36       254\n",
      "           3       0.60      0.71      0.65       797\n",
      "           4       0.58      0.63      0.61       853\n",
      "           5       0.69      0.69      0.69       670\n",
      "           6       0.58      0.29      0.39        86\n",
      "           7       0.00      0.00      0.00         5\n",
      "           8       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.62      2717\n",
      "   macro avg       0.42      0.32      0.35      2717\n",
      "weighted avg       0.61      0.62      0.60      2717\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[  0   3   3   0   0   0   0   0   0]\n",
      " [  0  13  18   8   0   0   0   0   0]\n",
      " [  0   0  67 167  17   3   0   0   0]\n",
      " [  0   1  26 566 192  12   0   0   0]\n",
      " [  0   1   1 178 541 132   0   0   0]\n",
      " [  0   0   0  21 179 459  11   0   0]\n",
      " [  0   0   0   1   1  59  25   0   0]\n",
      " [  0   0   0   0   0   3   2   0   0]\n",
      " [  0   0   0   0   0   2   5   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "logit_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "logit_model.fit(X, y)\n",
    "logit_pred = logit_model.predict(X)\n",
    "logit_acc = accuracy_score(y, logit_pred)\n",
    "print(\"\\nLogistic Regression Accuracy: {:.4f}\".format(logit_acc))\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y, logit_pred, target_names=[str(r) for r in unique_ratings]))\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y, logit_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
